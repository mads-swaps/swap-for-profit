{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataset import Dataset, to_device\n",
    "from model import ResNet28\n",
    "from time import time\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Predict Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "\n",
    "class CustomScaler1():\n",
    "    standard_scaler = None\n",
    "    fit = False\n",
    "    stdcols = ['number_of_trades','volume','quote_asset_volume',\n",
    "               'taker_buy_base_asset_volume','taker_buy_quote_asset_volume',\n",
    "              ]\n",
    "    tostd = []\n",
    "    atr_max = 0\n",
    "    atr_diff_std = 0\n",
    "    rsi_diff_std = 0\n",
    "    \n",
    "    min_max_range=(-1, 1)\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.standard_scaler = StandardScaler()\n",
    "        \n",
    "    def fit(self, X):\n",
    "        for c in self.stdcols:\n",
    "            for v in X.columns:\n",
    "                if v.startswith(c):\n",
    "                    self.tostd.append(v)\n",
    "                \n",
    "        if len(self.tostd) > 0:\n",
    "            self.standard_scaler.fit(X[self.tostd])\n",
    "            \n",
    "        if 'atr' in X.columns:\n",
    "            self.atr_max = X['atr'].max()\n",
    "        if 'atr_diff' in X.columns:\n",
    "            self.atr_diff_std = X['atr_diff'].std()\n",
    "        if 'rsi_diff' in X.columns:\n",
    "            self.rsi_diff_std = X['rsi_diff'].std()\n",
    "            \n",
    "        self.fit = True\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X_in):\n",
    "        if self.fit == True:\n",
    "            X = X_in.copy()\n",
    "            open_price = X['open'].copy()\n",
    "            stddev = (((X['close'] - X['open'])**2 + \\\n",
    "                       (X['high'] - X['open'])**2 + \\\n",
    "                       (X['low'] - X['open'])**2) / 3)**0.5\n",
    "            stddev = stddev.apply(lambda x: 1 if x==0 else x)\n",
    "            \n",
    "            for c in X.columns:\n",
    "                if c in ['open','high','low','close'] or \\\n",
    "                   re.match('open_[0-9]+', c) or \\\n",
    "                   re.match('high_[0-9]+', c) or \\\n",
    "                   re.match('low_[0-9]+', c) or \\\n",
    "                   re.match('close_[0-9]+', c) or \\\n",
    "                   re.match('sup[0-9]+', c) or \\\n",
    "                   re.match('res[0-9]+', c) or \\\n",
    "                   re.match('ma[0-9]+', c):\n",
    "                    X[c] = (X[c]-open_price)/stddev\n",
    "                elif c.startswith('atr_diff') and self.atr_diff_std>0:\n",
    "                    X[c] = X[c]/self.atr_diff_std\n",
    "                elif re.match('atr$|atr_[0-9]+|atr_ma[0-9]+',c):\n",
    "                    X[c] = X[c]/self.atr_max\n",
    "                elif c.startswith('rsi_diff') and self.rsi_diff_std>0:\n",
    "                    X[c] = X[c]/self.rsi_diff_std\n",
    "                elif re.match('rsi$|rsi_[0-9]+|rsi_ma[0-9]+',c):\n",
    "                    X[c] = (X[c]-50)/20 # thus the 30/70 thresholds will become -1/1\n",
    "            \n",
    "            if 'dow' in X.columns:\n",
    "                X['dow'] = X['dow'] / 6\n",
    "                \n",
    "            if len(self.tostd) > 0:\n",
    "                X[self.tostd] = self.standard_scaler.transform(X[self.tostd])\n",
    "            return X\n",
    "        else:\n",
    "            raise Exception('ModelScaler not yet fit')\n",
    "            \n",
    "    def fit_transform(self, X_in):\n",
    "        self.fit(X_in)\n",
    "        return self.transform(X_in)\n",
    "\n",
    "class CustomScaler2():\n",
    "    stdcols = ('number_of_trades','volume','quote_asset_volume',\n",
    "               'taker_buy_base_asset_volume','taker_buy_quote_asset_volume',\n",
    "               )\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.standard_scaler = StandardScaler()\n",
    "        self.tostd = []\n",
    "        self.is_fit = False\n",
    "        \n",
    "    def fit(self, X):\n",
    "        for c in self.stdcols:\n",
    "            for v in X.columns:\n",
    "                if v.startswith(c):\n",
    "                    self.tostd.append(v)\n",
    "                \n",
    "        if len(self.tostd) > 0:\n",
    "            self.standard_scaler.fit(X[self.tostd])\n",
    "            \n",
    "        self.is_fit = True\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X_in):\n",
    "        if self.is_fit == True:\n",
    "            X = X_in.copy()\n",
    "            open_price = X['open'].copy()\n",
    "            stddev = (((X['close'] - X['open'])**2 + \\\n",
    "                       (X['high'] - X['open'])**2 + \\\n",
    "                       (X['low'] - X['open'])**2) / 3)**0.5\n",
    "            stddev = stddev.apply(lambda x: 1 if x==0 else x)\n",
    "            \n",
    "            rsi_values = X['rsi'].copy()\n",
    "            atr_values = X['atr'].copy()\n",
    "            atr_values = atr_values.apply(lambda x: 1 if x==0 else x)\n",
    "            \n",
    "            for c in X.columns:\n",
    "                if c in ['open','high','low','close'] or \\\n",
    "                   re.match('open_[0-9]+', c) or \\\n",
    "                   re.match('high_[0-9]+', c) or \\\n",
    "                   re.match('low_[0-9]+', c) or \\\n",
    "                   re.match('close_[0-9]+', c) or \\\n",
    "                   re.match('sup[0-9]+', c) or \\\n",
    "                   re.match('res[0-9]+', c) or \\\n",
    "                   re.match('ma[0-9]+', c):\n",
    "                    X[c] = (X[c]-open_price)/stddev\n",
    "                elif c.startswith('atr_diff'):\n",
    "                    X[c] = X[c]/atr_values\n",
    "                elif re.match('atr$|atr_[0-9]+|atr_ma[0-9]+',c):\n",
    "                    X[c] = X[c]-atr_values/atr_values\n",
    "                elif c.startswith('rsi_diff'):\n",
    "                    X[c] = X[c]/rsi_values\n",
    "                elif re.match('rsi$|rsi_[0-9]+|rsi_ma[0-9]+',c):\n",
    "                    X[c] = (X[c]-50)/20 # thus the 30/70 thresholds will become -1/1\n",
    "            \n",
    "            if 'dow' in X.columns:\n",
    "                X['dow'] = X['dow'] / 6\n",
    "                \n",
    "            if len(self.tostd) > 0:\n",
    "                X[self.tostd] = self.standard_scaler.transform(X[self.tostd])\n",
    "            return X\n",
    "        else:\n",
    "            raise Exception('CustomScaler not yet fit')\n",
    "            \n",
    "    def fit_transform(self, X_in, y=None):\n",
    "        self.fit(X_in)\n",
    "        y=self.transform(X_in)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_only(config):\n",
    "    path = config.get('model_path', '')\n",
    "    f = f\"{path}/{config['model_identifier']}.pth\"\n",
    "    checkpoint = torch.load(f)\n",
    "    net = checkpoint['net']\n",
    "    scaler = checkpoint.get('scaler', None)\n",
    "    mean_losses = checkpoint['mean_losses']\n",
    "    return net, scaler, mean_losses\n",
    "\n",
    "def predict(model, X, y, device='cpu', silent=False):\n",
    "    pyt_device = torch.device(device)\n",
    "\n",
    "    if 'cuda' in device:\n",
    "        # Since it doesn't all fit on the GPU, we'll use a dataloader\n",
    "        batch_size = 2000\n",
    "        predictDataset = Dataset(X, y)\n",
    "        predictLoader = torch.utils.data.DataLoader(dataset=predictDataset,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False,\n",
    "                                                  num_workers=5,\n",
    "                                                  pin_memory=True\n",
    "                                                 )\n",
    "        num_elements = len(predictLoader.dataset)\n",
    "        num_outputs = len(y.columns)\n",
    "        num_batches = len(predictLoader)\n",
    "        predictions = torch.zeros(num_elements, num_outputs)\n",
    "        for i, (inputs, _) in tqdm(enumerate(predictLoader), total=num_batches, disable=silent):\n",
    "            inputs = to_device(inputs, pyt_device)\n",
    "            start = i*batch_size\n",
    "            end = start + batch_size\n",
    "            if i == num_batches - 1:\n",
    "                end = num_elements\n",
    "            pred = torch.round(torch.sigmoid(model(inputs)))\n",
    "            predictions[start:end] = pred.detach().cpu()\n",
    "        nn_results = predictions.numpy()\n",
    "    else:\n",
    "        if type(X) == np.ndarray:\n",
    "            X_tensor = torch.from_numpy(X).float()\n",
    "        else:\n",
    "            X_tensor = torch.from_numpy(X.to_numpy()).float()\n",
    "        nn_results = torch.round(torch.sigmoid(model(X_tensor))).detach().numpy()\n",
    "\n",
    "    return nn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_stoploss(df, threshold_ratio=(0.04,0.02), use_atr=True, atr_ratio=(2,1), reverse=False):\n",
    "    if not reverse:\n",
    "        if use_atr:\n",
    "            stop_losses = df.low-(df.atr*atr_ratio[1])\n",
    "            targets = df.close+(df.atr*atr_ratio[0])\n",
    "        else:\n",
    "            stop_losses = df.close-df.close*threshold_ratio[1]\n",
    "            targets = df.close+df.close*threshold_ratio[0]\n",
    "    else:\n",
    "        if use_atr:\n",
    "            stop_losses = df.high+(df.atr*atr_ratio[1])\n",
    "            targets = df.close-(df.atr*atr_ratio[0])\n",
    "        else:\n",
    "            stop_losses = df.close+df.close*threshold_ratio[1]\n",
    "            targets = df.close-df.close*threshold_ratio[0]\n",
    "\n",
    "    return targets, stop_losses\n",
    "\n",
    "def get_decisions_and_prices(x_data, pred, info_dict):\n",
    "    next_action = 1\n",
    "    target = -1\n",
    "    stoploss = -1\n",
    "    \n",
    "    if type(x_data.index) != pd.RangeIndex:\n",
    "        x_data = x_data.reset_index(drop=True)\n",
    "    \n",
    "    if type(pred) in (pd.DataFrame, pd.Series):\n",
    "        pred = pred.to_numpy().ravel()\n",
    "\n",
    "    use_atr = info_dict['model_use_atr']\n",
    "    atr_ratio = info_dict['model_ratio']\n",
    "    threshold_ratio = info_dict['model_ratio']\n",
    "    reverse = info_dict['model_reverse']\n",
    "        \n",
    "    targets, stop_losses = get_target_stoploss(x_data,\n",
    "                                               use_atr=use_atr,\n",
    "                                               atr_ratio=atr_ratio,\n",
    "                                               threshold_ratio=threshold_ratio,\n",
    "                                               reverse=reverse)\n",
    "    low_prices = x_data['low'].to_numpy()\n",
    "    high_prices = x_data['high'].to_numpy()\n",
    "    \n",
    "    # Decisions:\n",
    "    # 1 = buy\n",
    "    # 0 = hold (default)\n",
    "    # -1 = sell\n",
    "    decision = pd.Series(0, index=x_data.index)\n",
    "    execution_price = pd.Series(0.0, index=x_data.index)\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i>=len(x_data):\n",
    "            break\n",
    "        if next_action == 1:\n",
    "            # Find next buy opportunity\n",
    "            try:\n",
    "                next_buy_idx = np.where(pred[i:]==1)[0][0] + i\n",
    "                target = targets.iloc[next_buy_idx]\n",
    "                stoploss = stop_losses.iloc[next_buy_idx]\n",
    "                decision.at[next_buy_idx] = 1\n",
    "                execution_price.at[next_buy_idx] = x_data.loc[next_buy_idx, 'close']\n",
    "                i = next_buy_idx+1\n",
    "                next_action = -1\n",
    "            except:\n",
    "                # No more buy opportunties\n",
    "                break\n",
    "        else:\n",
    "            # Find next sell opportunity\n",
    "            try:\n",
    "                if not reverse:\n",
    "                    next_sell_idx = np.where((high_prices[i:]>=target) | (low_prices[i:]<=stoploss))[0][0] + i\n",
    "                else:\n",
    "                    next_sell_idx = np.where((low_prices[i:]<=target) | (high_prices[i:]>=stoploss))[0][0] + i\n",
    "                if x_data.loc[next_sell_idx, 'low'] <= target <= x_data.loc[next_sell_idx, 'high']:\n",
    "                    execution_price.at[next_sell_idx] = target\n",
    "                else:\n",
    "                    execution_price.at[next_sell_idx] = stoploss\n",
    "                decision.at[next_sell_idx] = -1\n",
    "                i = next_sell_idx+1\n",
    "                next_action = 1\n",
    "            except:\n",
    "                # No more sell opportunties\n",
    "                break\n",
    "\n",
    "    return decision, execution_price\n",
    "\n",
    "def simulate(in_df, starting_value, trading_fees_percent, trading_fees_buy, trading_fees_sell):\n",
    "    df = in_df.copy()\n",
    "    df['value'] = 0.0\n",
    "    value = starting_value\n",
    "    fee_multiplier = 1.0 - trading_fees_percent / 100\n",
    "\n",
    "    for x,r in df.iterrows():\n",
    "        if r.decision == 1 and value > 0:\n",
    "            value = ((value-trading_fees_buy) * r.price) * fee_multiplier\n",
    "            if value < 0:\n",
    "                break\n",
    "        elif r.decision == -1 and value > 0:\n",
    "            value = ((value-trading_fees_sell) / r.price) * fee_multiplier\n",
    "            if value < 0:\n",
    "                break\n",
    "        else:\n",
    "            break # value is below zero\n",
    "        df.loc[x,'value'] = value\n",
    "    return df.value\n",
    "\n",
    "def run_simulator(X, y, model_use_atr, model_ratio, model_reverse,\n",
    "                  starting_value=1, trading_fees_percent=0.1,\n",
    "                  trading_fees_buy=0, trading_fees_sell=0):\n",
    "    df = X.copy()\n",
    "    d = dict(model_use_atr=model_use_atr, model_ratio=model_ratio, model_reverse=model_reverse)\n",
    "    \n",
    "    decision, execution_price = get_decisions_and_prices(X, y, d)\n",
    "    \n",
    "    df['decision'] = decision.values\n",
    "    df['price'] = execution_price.values\n",
    "    \n",
    "    sim_df = df[df['decision']!=0][['decision','price']].copy()\n",
    "    if len(sim_df) == 0:\n",
    "        return starting_value\n",
    "    else:\n",
    "        sim_df['value'] = simulate(sim_df, starting_value, trading_fees_percent, trading_fees_buy, trading_fees_sell)\n",
    "        return sim_df[sim_df.decision==-1].value.to_numpy()[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Drop columns with lookbacks equal to or greater than X\n",
    "def get_columns(x=14):\n",
    "    columns = list(X_train.columns)\n",
    "    for c in X_train.columns:\n",
    "        if m := re.match(r'^.*_([0-9]+)$', c):\n",
    "            if int(m[1]) > x:\n",
    "                columns.remove(c)\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, train_idx=None, test_idx=None):\n",
    "    X_train = X.loc[train_idx]\n",
    "    y_train = y.loc[train_idx]\n",
    "    X_test = X.loc[test_idx]\n",
    "    y_test = y.loc[test_idx]\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "def load_split_data(suffix, split=False):\n",
    "    X = pd.read_pickle(f'../data/X_{suffix}.pkl')\n",
    "    y = pd.read_pickle(f'../data/y_{suffix}.pkl')\n",
    "    if split:\n",
    "        X_train, y_train, X_test, y_test = train_test_split(X, y, X.loc['2018':'2020'].index, X.loc['2021':].index)\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    else:\n",
    "        return X, y\n",
    "    \n",
    "X_train, y_train, X_test, y_test = load_split_data(suffix='20210806i', split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8bd05cced44f238d1b18c419ea52f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha8: Prec 0.4317 Recall 0.1799 F1 0.254 Profit 0.1484 Number 3419.0 Perc% 0.1707\n",
      "alpha9: Prec 0.4122 Recall 0.5837 F1 0.4832 Profit 0.062 Number 11619.0 Perc% 0.5802\n",
      "alpha10: Prec 0.4056 Recall 0.5838 F1 0.4786 Profit 0.047 Number 11811.0 Perc% 0.5898\n",
      "alpha11: Prec 0.4097 Recall 1.0 F1 0.5813 Profit 0.0234 Number 20025.0 Perc% 1.0\n",
      "alpha12: Prec 0.0 Recall 0.0 F1 0.0 Profit 1 Number 0.0 Perc% 0.0\n",
      "alpha13: Prec 0.412 Recall 0.9226 F1 0.5696 Profit 0.0321 Number 18375.0 Perc% 0.9176\n",
      "alpha14: Prec 0.4081 Recall 0.4803 F1 0.4413 Profit 0.0604 Number 9657.0 Perc% 0.4822\n",
      "alpha15: Prec 0.4204 Recall 0.2973 F1 0.3483 Profit 0.1023 Number 5802.0 Perc% 0.2897\n",
      "alpha16: Prec 0.4146 Recall 0.8329 F1 0.5536 Profit 0.0305 Number 16485.0 Perc% 0.8232\n",
      "alpha17: Prec 0.4081 Recall 0.771 F1 0.5337 Profit 0.0377 Number 15500.0 Perc% 0.774\n",
      "alpha18: Prec 0.4133 Recall 0.7561 F1 0.5344 Profit 0.0479 Number 15012.0 Perc% 0.7497\n",
      "alpha19: Prec 0.4129 Recall 0.5695 F1 0.4787 Profit 0.0448 Number 11317.0 Perc% 0.5651\n",
      "alpha20: Prec 0.442 Recall 0.2342 F1 0.3062 Profit 0.2091 Number 4348.0 Perc% 0.2171\n",
      "alpha21: Prec 0.4421 Recall 0.0726 F1 0.1248 Profit 0.3994 Number 1348.0 Perc% 0.0673\n",
      "alpha22: Prec 0.0 Recall 0.0 F1 0.0 Profit 1 Number 0.0 Perc% 0.0\n",
      "alpha23: Prec 1.0 Recall 0.0001 F1 0.0002 Profit 1.0037 Number 1.0 Perc% 0.0\n",
      "alpha24: Prec 0.5034 Recall 0.1361 F1 0.2143 Profit 0.6418 Number 2219.0 Perc% 0.1108\n",
      "alpha25: Prec 0.5199 Recall 0.043 F1 0.0795 Profit 0.887 Number 679.0 Perc% 0.0339\n",
      "alpha26: Prec 0.0 Recall 0.0 F1 0.0 Profit 1 Number 0.0 Perc% 0.0\n",
      "alpha27: Prec 0.0 Recall 0.0 F1 0.0 Profit 1 Number 0.0 Perc% 0.0\n",
      "alpha28: Prec 0.5087 Recall 0.0717 F1 0.1256 Profit 0.6767 Number 1156.0 Perc% 0.0577\n",
      "alpha29: Prec 0.4158 Recall 0.3895 F1 0.4022 Profit 0.0899 Number 7686.0 Perc% 0.3838\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model_ids=[ #'alpha1', - columns??\n",
    "            #'alpha2', - columns??\n",
    "            #'alpha3', - columns??\n",
    "            #'alpha4',  # Data = 20210726 - columns??\n",
    "            #'alpha5',  # Data = 20210726 - columns??\n",
    "            #'alpha6',  # Data = 20210726 - columns??\n",
    "            #'alpha7',  # Data = 20210729a - columns??\n",
    "            'alpha8',  # Data = 20210801f\n",
    "            'alpha9',  # Data = 20210801f\n",
    "            'alpha10',  # Data = 20210801f - \n",
    "            'alpha11',  # Data = 20210801f - CustomScaler1\n",
    "            'alpha12',  # Data = 20210801f - CustomScaler1\n",
    "            'alpha13',  # Data = 20210801f - NNModelEx\n",
    "            'alpha14',\n",
    "            'alpha15',\n",
    "            'alpha16',\n",
    "            'alpha17',\n",
    "            'alpha18',\n",
    "            'alpha19',\n",
    "            'alpha20',  # Data = 20210806i - CustomScaler2\n",
    "            'alpha21',\n",
    "            'alpha22',\n",
    "            'alpha23',\n",
    "            'alpha24',\n",
    "            'alpha25',\n",
    "            'alpha26',\n",
    "            'alpha27',\n",
    "            'alpha28',\n",
    "            'alpha29',\n",
    "          ]\n",
    "\n",
    "\n",
    "def get_metrics(model_id, X_test, y_test):\n",
    "    with open(f'models/{model_id}.cfg') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    model, scaler, _ = load_model_only(config)\n",
    "    \n",
    "    lookbacks = config.get('lookbacks',14)\n",
    "    columns = get_columns(lookbacks)\n",
    "    \n",
    "    if scaler is not None:\n",
    "        try:\n",
    "            X = scaler.transform(X_test[columns].copy())\n",
    "        except Exception as e:\n",
    "            print('Failed on ', model_id, 'Columns:', columns, 'Config', config)\n",
    "            raise e\n",
    "    else:\n",
    "        X = X_test[columns]\n",
    "    \n",
    "    predictions = predict(model, X, y_test, device=config['device'], silent=True)\n",
    "    predictions = np.nan_to_num(predictions)\n",
    "    \n",
    "    precision = precision_score(y_test, predictions, zero_division=0)\n",
    "    recall = recall_score(y_test, predictions, zero_division=0)\n",
    "    f1score = f1_score(y_test, predictions, zero_division=0)\n",
    "    num = predictions.sum()\n",
    "    perc = num/len(predictions)\n",
    "    profit = run_simulator(X_test, predictions, model_use_atr=True, model_ratio=(2,1), model_reverse=True)\n",
    "    return {'Prec':precision, 'Recall':recall, 'F1':f1score, 'Profit':profit, 'Number':num, 'Perc%':perc}\n",
    "\n",
    "\n",
    "for model_id in tqdm(model_ids):\n",
    "    vals = get_metrics(model_id, X_test, y_test)\n",
    "    \n",
    "    print(f'{model_id}:',end='')\n",
    "    for k,v in vals.items():\n",
    "        print('',k,round(v,4), end='')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a37301a766647cdb9c758ef13356d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nm_torch1_alpha30: Prec 0.4143 Recall 0.3377 F1 0.3721 Profit 0.0761 Number 6689.0 Perc% 0.334\n",
      "nm_torch1_alpha31: Prec 0.5194 Recall 0.1027 F1 0.1716 Profit 0.6457 Number 1623.0 Perc% 0.081\n",
      "nm_torch1_alpha32: Prec 0.5805 Recall 0.0167 F1 0.0325 Profit 0.9454 Number 236.0 Perc% 0.0118\n",
      "nm_torch1_alpha33: Prec 0.4821 Recall 0.2344 F1 0.3154 Profit 0.3472 Number 3989.0 Perc% 0.1992\n",
      "nm_torch1_alpha34: Prec 0.0 Recall 0.0 F1 0.0 Profit 1 Number 0.0 Perc% 0.0\n",
      "nm_torch1_alpha35: Prec 0.4118 Recall 0.0026 F1 0.0051 Profit 1.0391 Number 51.0 Perc% 0.0025\n",
      "nm_torch1_alpha36: Prec 0.0 Recall 0.0 F1 0.0 Profit 1 Number 0.0 Perc% 0.0\n",
      "nm_torch1_alpha37: Prec 0.4723 Recall 0.1775 F1 0.258 Profit 0.424 Number 3083.0 Perc% 0.154\n",
      "nm_torch1_alpha38: Prec 0.5805 Recall 0.0167 F1 0.0325 Profit 0.9454 Number 236.0 Perc% 0.0118\n"
     ]
    }
   ],
   "source": [
    "model_ids=[\n",
    "    'nm_torch1_alpha30',\n",
    "    'nm_torch1_alpha31',\n",
    "    'nm_torch1_alpha32',\n",
    "    'nm_torch1_alpha33',\n",
    "    'nm_torch1_alpha34',\n",
    "    'nm_torch1_alpha35',\n",
    "    'nm_torch1_alpha36',\n",
    "    'nm_torch1_alpha37',\n",
    "    'nm_torch1_alpha38',\n",
    "]\n",
    "\n",
    "for model_id in tqdm(model_ids):\n",
    "    vals = get_metrics(model_id, X_test, y_test)\n",
    "    \n",
    "    print(f'{model_id}:',end='')\n",
    "    for k,v in vals.items():\n",
    "        print('',k,round(v,4), end='')\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
